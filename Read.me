# Pepper VR Teleoperation System

**Control a Pepper robot in real-time using Meta Quest 2 VR headset**

## ğŸ¯ Project Overview

This system allows you to teleoperate a SoftBank Robotics Pepper robot through a Meta Quest 2 VR headset. Control Pepper's arms, head, hands, and base movement using intuitive VR controllers, with live camera feed streamed back to the headset.

### Key Features
- âœ… Real-time arm mimicry using inverse kinematics
- âœ… Base movement with joystick controls
- âœ… Head tracking synchronized to VR headset
- âœ… Hand open/close with trigger controls
- âœ… Live camera feed from Pepper to VR
- âœ… Pre-programmed motions (wave, dance)
- âœ… Emergency stop safety system
- âœ… Low-latency WebSocket communication

---

## ğŸ“‹ Requirements

### Hardware
- **Pepper Robot** (NAOqi 2.5+)
- **Meta Quest 2** VR Headset
- **PC** running Windows/Linux/Mac with:
  - Python 3.8-3.11
  - Unity 2021.3+ with OpenXR
  - WiFi connection to Pepper

### Software Dependencies

#### Python (Backend)
```bash
pip install -r Python/requirements.txt
```
- qi==3.1.5 (Pepper communication)
- websockets==13.0 (Unity connection)
- Flask==3.1.2 (video streaming)
- opencv-python==4.12.0.88 (image processing)
- pynput==1.7.6 (keyboard testing)

#### Unity (Frontend)
- Unity 2021.3 LTS or newer
- OpenXR Plugin
- XR Interaction Toolkit
- NativeWebSocket package

---

## ğŸš€ Quick Start

### Step 1: Setup Python Environment

```bash
# Clone the repository
cd ~/Desktop/VR_PEPPER_ROBOT

# Create virtual environment
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r Python/requirements.txt
```

### Step 2: Find Pepper's IP Address

Press Pepper's chest button once - it will announce its IP address verbally.

Example: `192.168.1.100`

### Step 3: Test Connection (IMPORTANT - Do This First!)

```bash
# Test basic connectivity
python test_qi_connection.py

# Test with keyboard controls (recommended before VR)
python test_keyboard_control.py 192.168.1.100
```

**Keyboard Test Controls:**
- Arrow keys: Move base
- Q/E: Rotate
- W/A/S/D: Head control
- U/I/J/K: Arm control
- [/]/;/': Hand control
- 1: Wave animation
- P: Print status
- ESC: Emergency stop

### Step 4: Start the Server

```bash
python Python/main.py --ip 192.168.1.100
```

You should see:
```
âœ“ Successfully connected to Pepper via qi framework
âœ“ Stiffness set to 1.0
âœ“ Moving to Stand posture
ğŸ¤– Robot is ready for teleoperation
âœ“ Starting command server on WebSocket port 5000...
Starting video streaming server on http://0.0.0.0:8080/video_feed
```

### Step 5: Configure Unity

1. Open Unity project
2. Navigate to `Assets/Scripts/Core/PepperConnection.cs`
3. Update `serverIp` to your PC's IP address (not Pepper's!)
   ```csharp
   public string serverIp = "192.168.1.101"; // Your PC's IP
   ```
4. Build and deploy to Quest 2

### Step 6: Use VR Controls

**Movement:**
- Left joystick: Move Pepper forward/back/strafe
- Right joystick (X-axis): Rotate Pepper

**Arms:**
- Grip button: Enable arm mimicry (hold to control)
- Release grip: Return arm to idle

**Hands:**
- Trigger: Close hand (0 = open, full press = closed)

**Head:**
- Your head rotation: Pepper mimics (automatic)

---

## ğŸ“ Project Structure

```
VR_PEPPER_ROBOT/
â”œâ”€â”€ Python/                          # Backend server
â”‚   â”œâ”€â”€ main.py                      # Entry point
â”‚   â”œâ”€â”€ network/
â”‚   â”‚   â”œâ”€â”€ command_receiver.py      # WebSocket server
â”‚   â”‚   â””â”€â”€ video_streamer.py        # Camera streaming
â”‚   â”œâ”€â”€ pepper_control/
â”‚   â”‚   â”œâ”€â”€ pepper_controller.py     # Main controller (qi)
â”‚   â”‚   â”œâ”€â”€ arm_controller.py        # Arm movements
â”‚   â”‚   â”œâ”€â”€ base_controller.py       # Base/wheel movements
â”‚   â”‚   â”œâ”€â”€ head_controller.py       # Head movements
â”‚   â”‚   â”œâ”€â”€ hand_controller.py       # Hand open/close
â”‚   â”‚   â””â”€â”€ pre_motions.py           # Pre-programmed animations
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ joint_limits.py          # Safety limits
â”‚   â””â”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ Config/
â”‚   â””â”€â”€ pepper_joint_limits.json     # Robot joint constraints
â”œâ”€â”€ Unity/                           # VR Frontend
â”‚   â””â”€â”€ Assets/Scripts/
â”‚       â”œâ”€â”€ Core/
â”‚       â”‚   â”œâ”€â”€ PepperConnection.cs  # WebSocket client
â”‚       â”‚   â””â”€â”€ VRInputManager.cs    # Quest 2 input
â”‚       â”œâ”€â”€ Controls/
â”‚       â”‚   â”œâ”€â”€ ArmIKController.cs   # IK solver & arm control
â”‚       â”‚   â”œâ”€â”€ BaseMovementController.cs
â”‚       â”‚   â”œâ”€â”€ HandController.cs
â”‚       â”‚   â””â”€â”€ HeadController.cs
â”‚       â””â”€â”€ Utils/
â”‚           â””â”€â”€ IKSolver.cs          # Inverse kinematics
â”œâ”€â”€ test_qi_connection.py            # Connection test script
â”œâ”€â”€ test_keyboard_control.py         # Manual control tester
â”œâ”€â”€ CONVERSION_GUIDE.md              # naoqiâ†’qi migration guide
â””â”€â”€ README.md                        # This file
```

---

## ğŸ”§ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Meta Quest 2 VR Headset               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Unity VR App                            â”‚  â”‚
â”‚  â”‚  - Input Manager (controllers/headset)   â”‚  â”‚
â”‚  â”‚  - IK Solver (arm mimicry)               â”‚  â”‚
â”‚  â”‚  - Camera display (Pepper POV)           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚ WebSocket (Commands)
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            PC/Laptop (Python Server)            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Command Receiver (WebSocket)            â”‚  â”‚
â”‚  â”‚         â–¼                                 â”‚  â”‚
â”‚  â”‚  Pepper Controller (qi framework)        â”‚  â”‚
â”‚  â”‚  â”œâ”€ Arm Controller                       â”‚  â”‚
â”‚  â”‚  â”œâ”€ Base Controller                      â”‚  â”‚
â”‚  â”‚  â”œâ”€ Head Controller                      â”‚  â”‚
â”‚  â”‚  â”œâ”€ Hand Controller                      â”‚  â”‚
â”‚  â”‚  â””â”€ Pre-motion Player                    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Video Streamer (Flask HTTP)             â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚ TCP/IP (qi protocol)
                 â”‚ HTTP (video stream)
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Pepper Robot                       â”‚
â”‚  - NAOqi Services (ALMotion, ALVideoDevice)    â”‚
â”‚  - Camera, Arms, Base, Head, Hands             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› Troubleshooting

### Connection Issues

**"No route to host" error:**
```bash
# 1. Check Pepper is on
ping 192.168.1.100

# 2. Verify port is open
nc -zv 192.168.1.100 9559

# 3. Ensure same network
ip addr  # Check your IP
# Should be same subnet as Pepper (e.g., both 192.168.1.x)
```

**"qi import failed":**
```bash
pip uninstall qi
pip install qi==3.1.5
python -c "import qi; print('qi version:', qi.__version__)"
```

**Unity can't connect:**
- Make sure Python server is running FIRST
- Check firewall isn't blocking port 5000
- Verify you used your PC's IP, not Pepper's IP
- Try: `telnet YOUR_PC_IP 5000`

### Robot Behavior Issues

**Pepper not moving:**
- Check stiffness: Should see "Stiffness set to 1.0" in logs
- Autonomous Life might be active: Press chest button to disable
- Check joint limits in `Config/pepper_joint_limits.json`

**Arms moving erratically:**
- Increase `smoothingFactor` in `ArmIKController.cs`
- Check IK solver arm lengths match Pepper's dimensions
- Verify coordinate transformation settings

**Video feed not working:**
- Check Flask server is running (should see port 8080 message)
- Try accessing directly: `http://YOUR_PC_IP:8080/video_feed`
- Verify camera_id (0=top camera, 1=bottom camera)

### Performance Issues

**High latency:**
- Ensure all devices on same LAN (not WiFi to different routers)
- Reduce video resolution in `video_streamer.py`
- Increase `smoothingFactor` to reduce command frequency

**Robot lagging:**
- Check `movementSpeed` values aren't too high
- Monitor network bandwidth
- Reduce VR application frame rate if needed

---

## ğŸ” Safety Features

1. **Joint Limits:** All movements clamped to safe ranges
2. **Emergency Stop:** Triggered on disconnect or ESC key
3. **Stiffness Control:** Can disable motors quickly
4. **Command Validation:** Malformed commands are rejected
5. **Pre-motion Lock:** VR controls disabled during animations

---

## ğŸ“Š Testing Checklist

Before each session:
- [ ] Pepper battery > 30%
- [ ] Pepper on stable surface
- [ ] Clear area around robot
- [ ] Python server connected successfully
- [ ] Keyboard test passes
- [ ] Video feed visible
- [ ] Emergency stop tested
- [ ] VR controllers tracked properly

---

## ğŸš§ Known Limitations

- Camera feed is mono (not stereo 3D)
- Pre-motions are hardcoded (not dynamically loadable)
- No force feedback in VR controllers
- IK solver is 5-DOF (no full 6-DOF hand orientation)
- Maximum ~20 commands/second due to NAOqi limits

---

## ğŸ”® Future Enhancements

- [ ] Implement dance and other pre-motions
- [ ] Add VR HUD with status display
- [ ] Hand tracking (replace controllers)
- [ ] Multi-camera stereo vision
- [ ] Record and replay motion sequences
- [ ] Autonomous navigation waypoints
- [ ] Voice command integration
- [ ] NAO robot synchronization

---

## ğŸ“ License

This project is for educational and research purposes. Pepper and NAOqi are trademarks of SoftBank Robotics.

---

## ğŸ¤ Contributing

Contributions welcome! Please test thoroughly before submitting PRs.

---

## ğŸ“§ Support

For issues:
1. Check troubleshooting section
2. Review logs in Python console
3. Test with keyboard controller first
4. Verify network connectivity

---

## ğŸ“ Credits

Developed for VR-based robot teleoperation research.
Built with qi framework, Unity, and Meta Quest 2.

**Last Updated:** October 2025
**Version:** 1.0.0 (qi migration complete)